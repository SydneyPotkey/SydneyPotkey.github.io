{
  "hash": "f6a8017d18959a605daf8aae297d5b4c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 6\"\ndescription: \"Writing Functions\"\nauthor:\n  - name: Sydney Potkey\n    url: https://SydneyPotkey.github.io/\ndate: 06-04-2025\ncitation: \n  url: https://SydneyPotkey.github.io/Posts/06_04_25_Lab6/ \nimage: \"images/download.jpg\"\ndraft: false \n---\n\n# Spicy Function \n**Exercise 1:** Write a function that removes outliers in a dataset. The user\nshould be able to supply the dataset, the variables to remove outliers from, and\na threshold on the number of SDs away from the mean used to define outliers. \n*Hint 1: You will need to calculate a z-score to filter the values!*\n*Hint 2: You might want to consider specifying a default value (e.g., 3) for `sd_thresh`.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(purrr)\n\nremove_outliers <- function(data, ..., sd_thresh = 3) {\n  vars <- enquos(...)\n  \n  # get non numeric variables\n  non_numeric_var <- data |>\n    select(...) |>\n    map_lgl(~ !is.numeric(.x)) |>\n    keep(identity) |>\n    names()\n  \n    if(length(non_numeric_var) > 0) {\n      stop(\"non-numeric columns detected: \",\n           str_c(non_numeric_var, collapse = \", \"))\n    }\n  \n  data |>\n    mutate(across(.cols = c(...),\n                  .fns = ~ (.x / mean(.x)) / sd(.x),\n                  .names = \"{.col}_scaled\")\n           ) |>\n    filter(if_any(.cols = ends_with(\"scaled\"),\n                  .fns = ~ .x < sd_thresh)) |>\n    select(- ends_with(\"scaled\"))\n}\n```\n:::\n\nwebsite I found helpful -> https://rlang.r-lib.org/reference/enquo.html\n\n## Testing Your Function! \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Testing how your function handles multiple input variables\nremove_outliers(diamonds, \n                price, \n                x, \n                y, \n                z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\n## Testing how your function handles an input that isn't numeric\nremove_outliers(diamonds, \n                price, \n                color)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in remove_outliers(diamonds, price, color): non-numeric columns detected: color\n```\n\n\n:::\n\n```{.r .cell-code}\n## Testing how your function handles a non-default sd_thresh\nremove_outliers(diamonds, \n                price,\n                x, \n                y, \n                z, \n                sd_thresh = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 53,930 more rows\n```\n\n\n:::\n:::\n\n# Vector Functions\n\n**Question 1:** The `rescale01()` function below performs a min-max scaling to \nstandardize a numeric vector, but infinite values are left unchanged. Rewrite\n`rescale01()` so that `-Inf` is mapped to 0, and `Inf` is mapped to 1?\n*Hint: This seems like a great place for `case_when()`!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrescale01 <- function(x) {\n  rng <- range(x, na.rm = TRUE, finite = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n  case_when(x == -Inf ~ 0,\n    x == Inf ~ 1,\n    TRUE ~ scaled)\n}\n```\n:::\n\n\n**Question 2:** Write a function that accepts a vector of birthdates and \ncomputes the age of each person in years.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(lubridate)\n\ncompute_age <- function(dates){\n  today <- Sys.Date() \n  age <- as.numeric(difftime(today,\n                             dates,\n                             units = \"weeks\")) / 52.25\nreturn(age)\n}\n```\n:::\n\n\n**Question 3:** Write a function that computes the variance and skewness of a\nnumeric vector. Feel free to look up the definitions on Wikipedia or elsewhere!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_and_skew <- function(vec){\n  n <- length(vec)\n  s <- sd(vec)\n  var <- sum((vec - mean(vec))^2 / (n-1))\n  skew <- sum((vec - mean(vec))^3 / (n-1)*s^3)\n  \n  return(list(variance = var, skewness = skew))\n}\n```\n:::\n\n\n**Question 4:** Write a function called `both_na()` which takes two vectors of\nthe same length and returns the number of positions that have an `NA` in both\nvectors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboth_na <- function(vec1, vec2){\n  sum(is.na(vec1) + is.na(vec2))\n}\n```\n:::\n\n\n## Data Frame Functions\n\n**Question 5:** Insert the data frame function you wrote from Lab 6 (either\nExercise 1 or Exercise 2). \n\n\n::: {.cell}\n\n```{.r .cell-code}\nremove_outliers <- function(data, ..., sd_thresh = 3) {\n  vars <- enquos(...)\n  \n  # check variable type\n  for (var in vars) {\n    col <- eval_tidy(var, data)\n    if (!is.numeric(col)) {\n      return(NA)\n    }\n  }\n  \n  keep <- rep(TRUE, nrow(data))\n  for (var in vars) {\n    col <- eval_tidy(var, data)\n    z <- (col - mean(col)) / sd(col)\n    keep <- keep & abs(z) <= sd_thresh\n  }\n  \n  return(data[keep, ])\n}\n```\n:::\n\n\nFor Questions 6 - 10 you will write different functions which work with data \nsimilar to the `nycflights13` data. \n\n**Question 6:** Write a `filter_severe()` function that finds all flights that\nwere cancelled (i.e. `is.na(arr_time)`) or delayed by more than an hour.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nycflights13)\n\nfilter_severe <- function(data){\n  severe_data <- filter(is.na(arr_time) | arr_delay > 60)\n}\n```\n:::\n\n\n**Question 7:** Write a `summarize_severe()` function that counts the number of \ncancelled flights and the number of flights delayed by more than an hour.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize_severe <- function(severe_data){\n  cancelled <- sum(is.na(arr_time))\n  delayed <- nrow(severe_data) - cancelled\n  \n  return(list(cancelled = cancelled, delayed = delayed))\n}\n```\n:::\n\n\n**Question 8:** Modify your `filter_severe()` function to allow the user to \nsupply the number of hours that should be used to filter the flights that were\ncancelled or delayed. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsevere_modified <- function(data, hours){\n  severe_data <- filter(is.na(arr_time) | arr_delay > hours)\n  \n}\n```\n:::\n\n\n**Question 9:** Write a `summarize_weather()` function that summarizes the\nweather to compute the minimum, mean, and maximum, of a user supplied variable. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize_weather <- function(var){\n  min <- min(var)\n  mean <- mean(var)\n  max <- max(var)\n  \n  return(list(minimum = min, mean = mean, maximum = max))\n}\n```\n:::\n\n\n**Question 10:** Write a `standardize_time()` function that converts the user\nsupplied variable that uses clock time (e.g., `dep_time`, `arr_time`, etc.) into\na decimal time (i.e. hours + (minutes / 60)).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstandardize_time <- function(time_var){\n  hours <- time_var %/% 100\n  minutes <- time_var %% 100\n  time <- hours + (minutes / 60)\n    \n  return(time)\n}\n```\n:::\n\n\n# Plotting Functions\n\nYou might want to read over the [Plot Functions section of *R for Data Science*](https://r4ds.hadley.nz/functions.html#plot-functions)\n\n**Question 11:** Build a `sorted_bars()` function which:\n\n- takes a data frame and a variable as inputs and returns a **vertical** bar\nchart \n- sorts the bars in decreasing order (largest to smallest)\n- adds a title that includes the context of the variable being plotted\n\n*Hint 1: The `fct_infreq()` and `fct_rev()` functions from the forcats package will be helpful for sorting the bars!*\n*Hint 2: The `englue()` function from the rlang package will be helpful for adding a variable's name into the plot title!*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\nlibrary(rlang)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'rlang'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:purrr':\n\n    %@%, flatten, flatten_chr, flatten_dbl, flatten_int, flatten_lgl,\n    flatten_raw, invoke, splice\n```\n\n\n:::\n\n```{.r .cell-code}\nsorted_bars <- function(data, var){\n  data |>\n    mutate({{ var }} := fct_rev(fct_infreq({{ var }}))) |>\n    ggplot(aes(y = {{var}})) +\n    geom_bar() +\n    labs(title = englue(\"Bar chart of {{ var }}, sorted by frequency\"),\n      x = NULL,\n      y = \"Count\") +\n    theme_minimal()\n}\n```\n:::\n\n\n# Iteration\n\nAlright, now let's take our plotting function and iterate it! \n\n**Question 12:** Make a sorted barplot for every character variable in the `mpg`\ndataset (built into `ggplot2`). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1: Convert character columns to factors\nmpg_factored <- mpg |> \n  mutate(across(where(is.character), as.factor))\n\n# Step 2: Generate bar charts for each character/factor variable\nmpg_factored |> \n  select(where(is.factor)) |> \n  names() |> \n  map(~ sorted_bars(mpg_factored, .))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/question-12-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[2]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/question-12-2.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[3]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/question-12-3.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[4]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/question-12-4.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[5]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/question-12-5.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[6]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/question-12-6.png){width=672}\n:::\n:::\n\n\n# Contributing to the R for Data Science Community!\n\nThe functions you wrote for exercises 1-10 came from *R for Data Science*. You\ncould consider making a pull request to the repository for the solutions! ",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}